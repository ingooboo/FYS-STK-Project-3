{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0c34e4a",
   "metadata": {},
   "source": [
    "# Testing Grid Resolution\n",
    "\n",
    "- SGD-Adam PyTorch and Autograd\n",
    "- Best learning rate from test_0\n",
    "- Epoch = 100\n",
    "- Arcitecture still [2,2] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb140b45581c4d9da0757013aff71a13",
   "metadata": {},
   "source": [
    "## Setup and imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660f77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook setup: add repo root to path and import project helpers.\n",
    "import sys, os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30b8cf978d4f7bb6cdb7b40ea2b92a",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# CONFIGURATION INFORMATION : \n",
    "##################################################################################\n",
    "# NETWORK ARCITECTURE : \n",
    "num_hidden_neurons = [2,2]  # A simple network just for testing\n",
    "opt_met_pytorch    = 'SGD-adam'\n",
    "opt_met_autograd   = 'SGD-adam'\n",
    "# HYPERPARAMETERS : \n",
    "epochs         = 100   \n",
    "learning_rate  = 0.01 # Concluded this is the best\n",
    "seed           = 36   # Most similar seed for numpy.random.seed and PyTorch.manual_seed\n",
    "# ONLY FOR SGD : \n",
    "batch_fraction = 0.012\n",
    "Nx_testing = [10, 30, 60, 90, 120] # Spatial resolution of Rod\n",
    "Nt_testing = [10, 30, 60, 90, 120] # Temporal lenght\n",
    "# MAKE X AND T (Just for config now): \n",
    "batch_size_list = []\n",
    "for Nx, Nt in zip(Nx_testing,Nt_testing):\n",
    "    t, x, t_torch, x_torch, batch_size = create_t_and_x_batch_size(Nx,\n",
    "                                                                   Nt,\n",
    "                                                                   batch_fraction)\n",
    "    batch_size_list.append(batch_size)\n",
    "# CONFIGURATION INFORMATION : \n",
    "config = make_config(Nx_testing,\n",
    "                     Nt_testing, \n",
    "                     num_hidden_neurons,\n",
    "                     opt_met_pytorch, \n",
    "                     epochs, \n",
    "                     learning_rate, \n",
    "                     batch_fraction,\n",
    "                     batch_size_list,\n",
    "                     seed,\n",
    "                     verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2ae469cc8c47788dea9d23c40d74a6",
   "metadata": {},
   "source": [
    "## Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb3f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# FUNCTION TO SET UP PARAMETERS :\n",
    "##################################################################################\n",
    "def set_up_test_grid_res(Nx,\n",
    "                         Nt, \n",
    "                         opt_met):\n",
    "    ##################################################################################\n",
    "    # MAKE X AND T : \n",
    "    ##################################################################################\n",
    "    t, x, t_torch, x_torch, batch_size = create_t_and_x_batch_size(Nx,\n",
    "                                                                   Nt,\n",
    "                                                                   batch_fraction)\n",
    "    ##################################################################################\n",
    "    # CONFIGURATION INFORMATION : \n",
    "    ##################################################################################\n",
    "    config = make_config(Nx,\n",
    "                         Nt, \n",
    "                         num_hidden_neurons,\n",
    "                         opt_met, \n",
    "                         epochs, \n",
    "                         learning_rate, \n",
    "                         batch_fraction,\n",
    "                         batch_size,\n",
    "                         seed,\n",
    "                         verbose=False)\n",
    "    return t, x, t_torch, x_torch, batch_size, config\n",
    "##################################################################################\n",
    "# FUNCTION TO TRAIN THE PINN :\n",
    "##################################################################################\n",
    "def compare_cost_and_time_A(optimization_method,\n",
    "                            learning_rate, \n",
    "                            t, \n",
    "                            x, \n",
    "                            batch_size):\n",
    "    start_time = time.time()\n",
    "    P, history = train_PINN_autograd(x,\n",
    "                                     t,\n",
    "                                     num_hidden_neurons,\n",
    "                                     epochs,\n",
    "                                     learning_rate,\n",
    "                                     'tanh',\n",
    "                                     seed,\n",
    "                                     optimization_method=optimization_method,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True,\n",
    "                                     replacement=False,\n",
    "                                     verbose=False,\n",
    "                                     debug=False)\n",
    "    end_time = time.time()\n",
    "    tot_time = end_time - start_time\n",
    "    return tot_time, history, P\n",
    "def compare_cost_and_time_P(optimization_method,\n",
    "                            learning_rate, \n",
    "                            t_torch, \n",
    "                            x_torch, \n",
    "                            batch_size):\n",
    "    start_time = time.time()\n",
    "    P, history = train_PINN_pyTorch(x_torch,\n",
    "                                    t_torch,\n",
    "                                    num_hidden_neurons,\n",
    "                                    epochs,\n",
    "                                    learning_rate,\n",
    "                                    'tanh',\n",
    "                                    seed,\n",
    "                                    optimization_method=optimization_method, \n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    replacement=False,\n",
    "                                    verbose=False,\n",
    "                                    debug=False)\n",
    "    end_time = time.time()\n",
    "    tot_time = end_time - start_time\n",
    "    return tot_time, history, P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf645699502747ffb73c7226155169df",
   "metadata": {},
   "source": [
    "## Run grid resolution sweep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe4bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train autograd and PyTorch PINNs across grid resolutions.\n",
    "results_A  = {}\n",
    "results_P  = {}\n",
    "for Nt, Nx in zip(Nt_testing, Nx_testing):\n",
    "    print('----------------------------------')\n",
    "    print(f'Nt, Nx : {Nt, Nx}')\n",
    "    print('----------------------------------')\n",
    "    ##################################################################################\n",
    "    # SET UP TEST GRID RESOLUTION : \n",
    "    ##################################################################################\n",
    "    t, x, t_torch, x_torch, batch_size, config = set_up_test_grid_res(Nx,\n",
    "                                                                      Nt,\n",
    "                                                                      opt_met_pytorch)\n",
    "    print(f'Batch size     : {batch_size}')\n",
    "    print(f'Learning rate  : {learning_rate}')\n",
    "    print(f'Implementation : {opt_met_pytorch}')\n",
    "    print()\n",
    "    ##################################################################################\n",
    "    # TRAIN PINN FOR EACH GRID RESOLUTION : \n",
    "    ##################################################################################\n",
    "    print('------------ Autograd ------------')\n",
    "    print('...')\n",
    "    print('------------ PyTorch ------------')\n",
    "    tot_timeP, historyP, PP = compare_cost_and_time_P(opt_met_pytorch,\n",
    "                                                      learning_rate, \n",
    "                                                      t_torch, \n",
    "                                                      x_torch, \n",
    "                                                      batch_size)\n",
    "    PINN_P_solution    = PINN_solution(Nx,Nt,x_torch,t_torch,Net,PP,num_hidden_neurons,'tanh','pytorch')\n",
    "    print('---------- Analytical ----------')\n",
    "    analytical_solut       = analytical_solution(Nx,Nt,x_torch,t_torch)\n",
    "    diff_PINN_P_analytic   = np.max(np.abs(PINN_P_solution - analytical_solut))\n",
    "    #results_A[(Nt, Nx)] = {'time': tot_timeA, 'history': historyA}#, 'P': PA}\n",
    "    results_P[(Nt, Nx)] = {'time': tot_timeP, 'history': historyP, 'P': PP, 'MAD': diff_PINN_P_analytic}\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836f340",
   "metadata": {},
   "source": [
    "## Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results and plot metrics vs grid resolution.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare lists\n",
    "Nx_list = []\n",
    "costs_P = []\n",
    "times_P = []\n",
    "mads_P = []\n",
    "\n",
    "for Nt, Nx in zip(Nt_testing, Nx_testing):\n",
    "    Nx_list.append(Nx)\n",
    "    costs_P.append(results_P[(Nt, Nx)]['history']['cost'][-1])\n",
    "    times_P.append(results_P[(Nt, Nx)]['time'])\n",
    "    entry = results_P[(Nt, Nx)]\n",
    "    if 'history' in entry and 'MAD' in entry['history']:\n",
    "        mads_P.append(entry['history']['MAD'][-1])\n",
    "    elif 'diff_PINN_P_analytic' in entry:\n",
    "        mads_P.append(entry['diff_PINN_P_analytic'])\n",
    "    elif 'MAD' in entry:\n",
    "        mads_P.append(entry['MAD'])\n",
    "    else:\n",
    "        # fallback: NaN so plotting won't crash\n",
    "        mads_P.append(np.nan)\n",
    "try:\n",
    "    x_vals = np.array(Nx_list, dtype=float)\n",
    "    xtick_labels = None\n",
    "except Exception:\n",
    "    x_vals = np.arange(len(Nx_list))\n",
    "    xtick_labels = Nx_list\n",
    "\n",
    "# Sort by x to ensure connected lines go left-to-right\n",
    "order = np.argsort(x_vals)\n",
    "x_sorted = x_vals[order]\n",
    "costs_P_sorted = np.array(costs_P)[order]\n",
    "times_P_sorted = np.array(times_P)[order]\n",
    "mads_P_sorted = np.array(mads_P)[order]\n",
    "nx_labels_sorted = np.array(Nx_list)[order] if xtick_labels is not None else None\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "# Left axis: Final Cost (with time annotations)\n",
    "hP, = ax.plot(x_sorted, costs_P_sorted, marker='s', linestyle='-', color='tab:red',\n",
    "              label='PyTorch Cost')\n",
    "for xi, cp, tp in zip(x_sorted, costs_P_sorted, times_P_sorted):\n",
    "    ax.annotate(f'{tp:.1f}s', xy=(xi, cp), xytext=(20, 8),\n",
    "                textcoords='offset points', ha='center', fontsize=12, color='tab:red')\n",
    "\n",
    "ax.set_xlabel('Nx Grid Resolution')\n",
    "ax.set_ylabel('Final Cost', color='tab:red')\n",
    "ax.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "# Right axis: MAD (no time annotation)\n",
    "ax2 = ax.twinx()\n",
    "hMAD, = ax2.plot(x_sorted, mads_P_sorted, marker='o', linestyle='--', color='tab:blue',\n",
    "                 label='PyTorch MAE')\n",
    "ax2.set_ylabel('MAE (diff_PINN_P_analytic)', color='tab:blue')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Combined legend\n",
    "ax.legend(handles=[hP, hMAD], loc='best')\n",
    "\n",
    "if xtick_labels is not None:\n",
    "    ax.set_xticks(x_sorted)\n",
    "    ax.set_xticklabels(nx_labels_sorted)\n",
    "\n",
    "plt.title(f'Final Cost and MAE vs Grid Resolution â€” {opt_met_pytorch} (epochs={epochs})')\n",
    "plt.tight_layout()\n",
    "save_fig('test1_cost_and_mad_vs_grid')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
